{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "def conecta_db():\n",
    "      con = psycopg2.connect(host='localhost', \n",
    "                         database='ctt2025',\n",
    "                         user='postgres', \n",
    "                         password='1983')\n",
    "      return con\n",
    "\n",
    "\n",
    "def criar_db(sql):\n",
    "    con = conecta_db()\n",
    "    cur = con.cursor()\n",
    "    cur.execute(sql)\n",
    "    con.commit()\n",
    "    con.close()\n",
    "\n",
    "\n",
    "def inserir_db(sql):\n",
    "    con = conecta_db()\n",
    "    cur = con.cursor()\n",
    "    try:\n",
    "        cur.execute(sql)\n",
    "        con.commit()\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(\"Error: %s\" % error)\n",
    "        con.rollback()\n",
    "        cur.close()\n",
    "        return 1\n",
    "    cur.close()\n",
    "\n",
    "sql = ''' CREATE TABLE IF NOT EXISTS Expresso_2025 (\n",
    "                                    DATA_CRIACAO      text,\n",
    "                                    CENTRO    text,\n",
    "                                    Giro text,\n",
    "                                    LOPTICA  text,\n",
    "                                    JANELA_HORARIA text,\n",
    "                                    NOME text,\n",
    "                                    MORADA text,\n",
    "                                    CP text,\n",
    "                                    LOCALIDADE text,\n",
    "                                    COD_T_EVEN text,\n",
    "                                    DATA_EVENTO text,\n",
    "                                    LATITUDE text,\n",
    "                                    LONGITUDE text,\n",
    "                                    NOME_REM text,\n",
    "                                    COD_PAIS_ORIGEM text,\n",
    "                                    DATA_PA text) '''\n",
    "criar_db(sql)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] The system cannot find the file specified",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     14\u001b[39m cmd = [\n\u001b[32m     15\u001b[39m     PG_DUMP_PATH,\n\u001b[32m     16\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m-h\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mlocalhost\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     21\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m-f\u001b[39m\u001b[33m\"\u001b[39m, output_file\n\u001b[32m     22\u001b[39m ]\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# Executa o comando no Windows pedindo a password\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43menviron\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPGPASSWORD\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m1983\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.2288.0_x64__qbz5n2kfra8p0\\Lib\\subprocess.py:554\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[39m\n\u001b[32m    551\u001b[39m     kwargs[\u001b[33m'\u001b[39m\u001b[33mstdout\u001b[39m\u001b[33m'\u001b[39m] = PIPE\n\u001b[32m    552\u001b[39m     kwargs[\u001b[33m'\u001b[39m\u001b[33mstderr\u001b[39m\u001b[33m'\u001b[39m] = PIPE\n\u001b[32m--> \u001b[39m\u001b[32m554\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[32m    555\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    556\u001b[39m         stdout, stderr = process.communicate(\u001b[38;5;28minput\u001b[39m, timeout=timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.2288.0_x64__qbz5n2kfra8p0\\Lib\\subprocess.py:1039\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[39m\n\u001b[32m   1035\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.text_mode:\n\u001b[32m   1036\u001b[39m             \u001b[38;5;28mself\u001b[39m.stderr = io.TextIOWrapper(\u001b[38;5;28mself\u001b[39m.stderr,\n\u001b[32m   1037\u001b[39m                     encoding=encoding, errors=errors)\n\u001b[32m-> \u001b[39m\u001b[32m1039\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1040\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1041\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1042\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1043\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1044\u001b[39m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1045\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1046\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1047\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1048\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m   1049\u001b[39m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[32m   1050\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m.stdin, \u001b[38;5;28mself\u001b[39m.stdout, \u001b[38;5;28mself\u001b[39m.stderr)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.2288.0_x64__qbz5n2kfra8p0\\Lib\\subprocess.py:1554\u001b[39m, in \u001b[36mPopen._execute_child\u001b[39m\u001b[34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session, unused_process_group)\u001b[39m\n\u001b[32m   1552\u001b[39m \u001b[38;5;66;03m# Start the process\u001b[39;00m\n\u001b[32m   1553\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1554\u001b[39m     hp, ht, pid, tid = \u001b[43m_winapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCreateProcess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1555\u001b[39m \u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# no special security\u001b[39;49;00m\n\u001b[32m   1556\u001b[39m \u001b[43m                             \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1557\u001b[39m \u001b[43m                             \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1558\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1559\u001b[39m \u001b[43m                             \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1560\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1561\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1562\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1563\u001b[39m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[32m   1564\u001b[39m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1567\u001b[39m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[32m   1568\u001b[39m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n\u001b[32m   1569\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_pipe_fds(p2cread, p2cwrite,\n\u001b[32m   1570\u001b[39m                          c2pread, c2pwrite,\n\u001b[32m   1571\u001b[39m                          errread, errwrite)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [WinError 2] The system cannot find the file specified"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# 1. Dump da base de dados PostgreSQL\n",
    "# ==========================\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Caminho do executável pg_dump\n",
    "PG_DUMP_PATH = r\"C:\\Program Files\\PostgreSQL\\17\\bin\\pg_dump.exe\"  # ajusta se for outra versão\n",
    "\n",
    "# Caminho do ficheiro de saída\n",
    "output_file = os.path.expanduser(r\"~\\Downloads\\backup_ctt2025_09.dump\")\n",
    "\n",
    "# Comando para executar o dump\n",
    "cmd = [\n",
    "    PG_DUMP_PATH,\n",
    "    \"-h\", \"localhost\",\n",
    "    \"-U\", \"postgres\",\n",
    "    \"-p\", \"5432\",\n",
    "    \"-d\", \"ctt2025\",\n",
    "    \"-F\", \"c\",  # formato custom (para pg_restore)\n",
    "    \"-f\", output_file\n",
    "]\n",
    "\n",
    "# Executa o comando no Windows pedindo a password\n",
    "subprocess.run(cmd, env={**os.environ, \"PGPASSWORD\": \"1983\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20250621' '20250622' '20250623' '20250624' '20250625' '20250626'\n",
      " '20250627' '20250628' '20250629' '20250630' '20250701' '20250702'\n",
      " '20250703' '20250704' '20250705' '20250706' '20250707' '20250708'\n",
      " '20250709' '20250731' '20250801' '20250802' '20250803' '20250804'\n",
      " '20250805' '20250806' '20250807' '20250808' '20250809' '20250810'\n",
      " '20250811' '20250812' '20250813' '20250814' '20250815' '20250816'\n",
      " '20250817' '20250818' '20250819' '20250820' '20250821' '20250822'\n",
      " '20250823' '20250824' '20250825' '20250826' '20250827' '20250828'\n",
      " '20250829' '20250830' '20250831' '20250901' '20250902' '20250903'\n",
      " '20250904' '20250905' '20250906' '20250907' '20250908' '20250909'\n",
      " '20250910' '20250911' '20250912' '20250913' '20250914' '20250915'\n",
      " '20250916' '20250917' '20250918' '20250919' '20250920' '20250921'\n",
      " '20250922' '20250923' '20250924' '20250925' '20250926' '20250927'\n",
      " '20250928' '20250929' '20250930' '20251001' '20251002' '20251003'\n",
      " '20251004' '20251005' '20251006' '20251007']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "data_validation = []\n",
    "con = conecta_db()\n",
    "cur = con.cursor()\n",
    "cur.execute(\"SELECT DISTINCT CONCAT(SUBSTRING(DATA_CRIACAO, 7, 4),SUBSTRING(DATA_CRIACAO, 4, 2),SUBSTRING(DATA_CRIACAO, 1, 2)) AS ConvertedDate FROM Expresso_2025\")\n",
    "for record in cur.fetchall():\n",
    "    if record[0] not in data_validation:\n",
    "        data_validation.append(record[0])\n",
    "cur.close()\n",
    "\n",
    "data_validation=np.array(data_validation)\n",
    "print(data_validation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expresso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'EVPDA3466_ENV_20251008_20251009010517.CSV' inserted into the database: 806.9606306552887 seconds\n",
      "File 'EVPDA3466_ENV_20251009_20251010010500.CSV' inserted into the database: 709.0417113304138 seconds\n"
     ]
    }
   ],
   "source": [
    "from ftplib import FTP\n",
    "import os\n",
    "import io\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "import time\n",
    "\n",
    "current_year = datetime.datetime.now().year\n",
    "\n",
    "ftp = FTP()\n",
    "ftp.connect(host='10.0.25.193', port=2122)\n",
    "ftp.login(user='cax_sgc', passwd='gy768#lo')\n",
    "\n",
    "ftp.cwd('/OP/Rotas/EventosPDA')\n",
    "\n",
    "files = ftp.nlst()\n",
    "\n",
    "def process_data(row):\n",
    "    try:\n",
    "        decoded_line = row.decode('Latin-1')\n",
    "    except UnicodeDecodeError as e:\n",
    "        print(f\"UnicodeDecodeError in file '{file}', line: {row}\")\n",
    "        decoded_line = row.decode('utf-8')\n",
    "    return decoded_line.strip()\n",
    "\n",
    "data_validation = []\n",
    "\n",
    "cur = con.cursor()\n",
    "\n",
    "cur.execute(\"SELECT distinct  SUBSTRING(DATA_CRIACAO, 7, 4) ||  SUBSTRING(DATA_CRIACAO, 4, 2) ||  SUBSTRING(DATA_CRIACAO, 1, 2) as dias FROM Expresso_2025 order by dias asc\")\n",
    "for record in cur.fetchall():\n",
    "    if record[0] not in data_validation:\n",
    "        data_validation.append(record[0])\n",
    "\n",
    "cur.close()\n",
    "\n",
    "for file in files:\n",
    "    start_time = time.time()\n",
    "    if file.startswith(\"E\"):\n",
    "        date_str_s = file[14:22].replace(\"/\", \"\")\n",
    "        ano = file[14:18]\n",
    "        mes = date_str_s[4:6]\n",
    "        date_str_s_array = np.array(date_str_s)\n",
    "        \n",
    "        if date_str_s not in data_validation and ano == \"2025\" and mes >= \"05\":\n",
    "            \n",
    "            ftp = FTP()\n",
    "            ftp.connect(host='10.0.25.193', port=2122)\n",
    "            ftp.login(user='cax_sgc', passwd='gy768#lo')\n",
    "            ftp.cwd('/OP/Rotas/EventosPDA')\n",
    "            \n",
    "            file_data = io.BytesIO()\n",
    "            ftp.retrbinary('RETR ' + file, file_data.write)\n",
    "            file_data.seek(0)  # Reset the stream position to the beginning\n",
    "\n",
    "            # Process the data line by line, excluding the last line\n",
    "            lines = file_data.readlines()\n",
    "            data_rows = [process_data(row) for row in lines[:-1]]  # Exclude the last line\n",
    "            df = pd.read_csv(io.StringIO('\\n'.join(data_rows)), sep=';', on_bad_lines='skip', encoding=\"Latin-1\")\n",
    "            ftp.quit()\n",
    "            \n",
    "            if len(data_rows) == 1: \n",
    "                continue\n",
    "            else:\n",
    "                # Insert the data into the database\n",
    "                for index, row in df.iterrows():\n",
    "                    try:\n",
    "                        cur = con.cursor()\n",
    "                        # Replace \"NaN\" values with None (NULL) for database insertion\n",
    "                        row = [None if pd.isna(value) else value for value in row]\n",
    "                        placeholders = ', '.join(['%s'] * len(row))\n",
    "                        insert_query = f\"INSERT INTO Expresso_2025 ({', '.join(df.columns)}) VALUES ({placeholders})\"\n",
    "                        cur.execute(insert_query, tuple(row))\n",
    "                    except (Exception, psycopg2.DatabaseError) as error:\n",
    "                        print(f\"Error inserting row {index+1}: {error}\")\n",
    "                        con.rollback()\n",
    "                    else:\n",
    "                        con.commit()\n",
    "                        \n",
    "                end_time = time.time()    \n",
    "                print(f\"File '{file}' inserted into the database: {end_time - start_time} seconds\")\n",
    "\n",
    "con.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom ftplib import FTP\\nimport io\\nimport pandas as pd\\nimport numpy as np\\nimport psycopg2\\nimport psycopg2.extras\\nimport time\\n\\n# --- ligações pré-existentes ---\\n# con = psycopg2.connect(...)\\n\\n# 1) validar dias já carregados (usa set para O(1))\\nwith con.cursor() as cur:\\n    cur.execute(\"\"\"\\n        SELECT DISTINCT SUBSTRING(DATA_CRIACAO, 7, 4) || SUBSTRING(DATA_CRIACAO, 4, 2) || SUBSTRING(DATA_CRIACAO, 1, 2) AS dias\\n        FROM Expresso_2025\\n    \"\"\")\\n    data_validation = {r[0] for r in cur.fetchall()}\\n\\n# 2) abrir uma única sessão FTP\\nftp = FTP()\\nftp.connect(host=\\'10.0.25.193\\', port=2122)\\nftp.login(user=\\'cax_sgc\\', passwd=\\'gy768#lo\\')\\nftp.cwd(\\'/OP/Rotas/EventosPDA\\')\\nfiles = ftp.nlst()\\n\\ndef process_data(row):\\n    try:\\n        return row.decode(\\'Latin-1\\').strip()\\n    except UnicodeDecodeError:\\n        return row.decode(\\'utf-8\\').strip()\\n\\ndef copy_df(conn, df, table):\\n    # COPY CSV para Postgres (muito mais rápido que INSERT por linha)\\n    buf = io.StringIO()\\n    # Se o teu CSV no destino deve usar \\';\\', mantém sep=\\';\\'\\n    df.to_csv(buf, index=False, header=False, sep=\\';\\')\\n    buf.seek(0)\\n    with conn.cursor() as c:\\n        c.copy_expert(f\"COPY {table} ({\\', \\'.join(df.columns)}) FROM STDIN WITH (FORMAT csv, DELIMITER \\';\\')\", buf)\\n\\n# 3) loop de ficheiros\\nfor file in files:\\n    if not file.startswith(\"E\"):\\n        continue\\n\\n    date_str_s = file[14:22].replace(\"/\", \"\")\\n    ano = file[14:18]\\n    mes = date_str_s[4:6]\\n\\n    # filtros rápidos para evitar trabalho desnecessário\\n    if not (ano == \"2025\" and mes >= \"05\"):\\n        continue\\n    if date_str_s in data_validation:\\n        continue\\n\\n    start_time = time.time()\\n\\n    # ler ficheiro do FTP uma única vez\\n    file_data = io.BytesIO()\\n    ftp.retrbinary(\\'RETR \\' + file, file_data.write)\\n    file_data.seek(0)\\n\\n    # processar linhas (ignorando a última se for trailer)\\n    lines = file_data.readlines()\\n    if len(lines) <= 1:\\n        continue\\n    data_rows = [process_data(row) for row in lines[:-1]]\\n\\n    # construir DataFrame (um parse por ficheiro)\\n    df = pd.read_csv(io.StringIO(\\'\\n\\'.join(data_rows)), sep=\\';\\', on_bad_lines=\\'skip\\', encoding=\"Latin-1\")\\n\\n    # normalizar NaN -> vazio (COPY trata bem) ou, se precisares de NULL, substitui por \\'\\'\\n    df = df.where(pd.notna(df), None)\\n\\n    # 4) transação por ficheiro + COPY\\n    try:\\n        con.autocommit = False\\n        copy_df(con, df, \"Expresso_2025\")\\n        con.commit()\\n        data_validation.add(date_str_s)  # marca como carregado\\n        print(f\"File \\'{file}\\' -> {len(df)} linhas, {time.time() - start_time:.1f}s\")\\n    except Exception as e:\\n        con.rollback()\\n        print(f\"ERRO em \\'{file}\\': {e}\")\\n\\n# fechar FTP e DB\\nftp.quit()\\ncon.close()\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from ftplib import FTP\n",
    "import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "import time\n",
    "\n",
    "# --- ligações pré-existentes ---\n",
    "# con = psycopg2.connect(...)\n",
    "\n",
    "# 1) validar dias já carregados (usa set para O(1))\n",
    "with con.cursor() as cur:\n",
    "    cur.execute(\"\"\"\n",
    "        SELECT DISTINCT SUBSTRING(DATA_CRIACAO, 7, 4) || SUBSTRING(DATA_CRIACAO, 4, 2) || SUBSTRING(DATA_CRIACAO, 1, 2) AS dias\n",
    "        FROM Expresso_2025\n",
    "    \"\"\")\n",
    "    data_validation = {r[0] for r in cur.fetchall()}\n",
    "\n",
    "# 2) abrir uma única sessão FTP\n",
    "ftp = FTP()\n",
    "ftp.connect(host='10.0.25.193', port=2122)\n",
    "ftp.login(user='cax_sgc', passwd='gy768#lo')\n",
    "ftp.cwd('/OP/Rotas/EventosPDA')\n",
    "files = ftp.nlst()\n",
    "\n",
    "def process_data(row):\n",
    "    try:\n",
    "        return row.decode('Latin-1').strip()\n",
    "    except UnicodeDecodeError:\n",
    "        return row.decode('utf-8').strip()\n",
    "\n",
    "def copy_df(conn, df, table):\n",
    "    # COPY CSV para Postgres (muito mais rápido que INSERT por linha)\n",
    "    buf = io.StringIO()\n",
    "    # Se o teu CSV no destino deve usar ';', mantém sep=';'\n",
    "    df.to_csv(buf, index=False, header=False, sep=';')\n",
    "    buf.seek(0)\n",
    "    with conn.cursor() as c:\n",
    "        c.copy_expert(f\"COPY {table} ({', '.join(df.columns)}) FROM STDIN WITH (FORMAT csv, DELIMITER ';')\", buf)\n",
    "\n",
    "# 3) loop de ficheiros\n",
    "for file in files:\n",
    "    if not file.startswith(\"E\"):\n",
    "        continue\n",
    "\n",
    "    date_str_s = file[14:22].replace(\"/\", \"\")\n",
    "    ano = file[14:18]\n",
    "    mes = date_str_s[4:6]\n",
    "\n",
    "    # filtros rápidos para evitar trabalho desnecessário\n",
    "    if not (ano == \"2025\" and mes >= \"05\"):\n",
    "        continue\n",
    "    if date_str_s in data_validation:\n",
    "        continue\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # ler ficheiro do FTP uma única vez\n",
    "    file_data = io.BytesIO()\n",
    "    ftp.retrbinary('RETR ' + file, file_data.write)\n",
    "    file_data.seek(0)\n",
    "\n",
    "    # processar linhas (ignorando a última se for trailer)\n",
    "    lines = file_data.readlines()\n",
    "    if len(lines) <= 1:\n",
    "        continue\n",
    "    data_rows = [process_data(row) for row in lines[:-1]]\n",
    "\n",
    "    # construir DataFrame (um parse por ficheiro)\n",
    "    df = pd.read_csv(io.StringIO('\\n'.join(data_rows)), sep=';', on_bad_lines='skip', encoding=\"Latin-1\")\n",
    "\n",
    "    # normalizar NaN -> vazio (COPY trata bem) ou, se precisares de NULL, substitui por ''\n",
    "    df = df.where(pd.notna(df), None)\n",
    "\n",
    "    # 4) transação por ficheiro + COPY\n",
    "    try:\n",
    "        con.autocommit = False\n",
    "        copy_df(con, df, \"Expresso_2025\")\n",
    "        con.commit()\n",
    "        data_validation.add(date_str_s)  # marca como carregado\n",
    "        print(f\"File '{file}' -> {len(df)} linhas, {time.time() - start_time:.1f}s\")\n",
    "    except Exception as e:\n",
    "        con.rollback()\n",
    "        print(f\"ERRO em '{file}': {e}\")\n",
    "\n",
    "# fechar FTP e DB\n",
    "ftp.quit()\n",
    "con.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BANCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "def conecta_db():\n",
    "      con = psycopg2.connect(host='localhost', \n",
    "                         database='ctt2025',\n",
    "                         user='postgres', \n",
    "                         password='1983')\n",
    "      return con\n",
    "\n",
    "\n",
    "def criar_db(sql):\n",
    "    con = conecta_db()\n",
    "    cur = con.cursor()\n",
    "    cur.execute(sql)\n",
    "    con.commit()\n",
    "    con.close()\n",
    "\n",
    "\n",
    "def inserir_db(sql):\n",
    "    con = conecta_db()\n",
    "    cur = con.cursor()\n",
    "    try:\n",
    "        cur.execute(sql)\n",
    "        con.commit()\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(\"Error: %s\" % error)\n",
    "        con.rollback()\n",
    "        cur.close()\n",
    "        return 1\n",
    "    cur.close()\n",
    "\n",
    "sql = ''' CREATE TABLE IF NOT EXISTS BANCA_2025 (\n",
    "                                    COD_CLIENTE_BNC text,\n",
    "                                    CODIGO_BALCAO_SIDIR text,\n",
    "                                    CODIGO_BALCAO_AF text,\n",
    "                                    AGENCIA text,\n",
    "                                    CA text,\n",
    "                                    CIRCUITO text,\n",
    "                                    DATA text,\n",
    "                                    CONTACTO text,\n",
    "                                    FATURAR text,\n",
    "                                    ENTREGUE text,\n",
    "                                    TAREFA text,\n",
    "                                    CP text,\n",
    "                                    CENTRO_OPERACIONAL text,\n",
    "                                    MORADA_TOQUE text,\n",
    "                                    HORA_TOQUE_PREVISTA text,\n",
    "                                    HORA_TOQUE_REAL text\n",
    "                                    ) '''\n",
    "criar_db(sql)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20250624' '20250625' '20250626' '20250627' '20250630' '20250701'\n",
      " '20250702' '20250703' '20250704' '20250707' '20250708' '20250709'\n",
      " '20250710' '20250711' '20250714' '20250715' '20250716' '20250717'\n",
      " '20250718' '20250721' '20250722' '20250723' '20250724' '20250725'\n",
      " '20250728' '20250729' '20250730' '20250731' '20250801' '20250804'\n",
      " '20250805' '20250806' '20250807' '20250808' '20250811' '20250812'\n",
      " '20250813' '20250814' '20250815' '20250818' '20250819' '20250820'\n",
      " '20250821' '20250822' '20250825' '20250826' '20250827' '20250828'\n",
      " '20250829' '20250901' '20250902' '20250903' '20250904' '20250905'\n",
      " '20250908' '20250909' '20250910' '20250911' '20250912' '20250915'\n",
      " '20250916' '20250917' '20250918' '20250919' '20250922' '20250923'\n",
      " '20250924' '20250925' '20250926' '20250929' '20250930' '20251001'\n",
      " '20251002' '20251003']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "data_validation = []\n",
    "con = conecta_db()\n",
    "cur = con.cursor(cursor_factory=psycopg2.extras.DictCursor)\n",
    "cur.execute(\"SELECT distinct REPLACE(data, '.', '') dias FROM Banca_2025 order by dias asc\")\n",
    "for record in cur.fetchall():\n",
    "    if record[0] not in data_validation:\n",
    "        data_validation.append(record[0])\n",
    "cur.close()\n",
    "\n",
    "data_validation=np.array(data_validation)\n",
    "print(data_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'CAX019_TOQUE_BANCA_D_20251006_20251007000639.CSV' inserted into the database: 19.024969577789307 seconds\n",
      "File 'CAX019_TOQUE_BANCA_D_20251007_20251008000608.CSV' inserted into the database: 0.7659471035003662 seconds\n",
      "File 'CAX019_TOQUE_BANCA_D_20251008_20251009000635.CSV' inserted into the database: 1.2202017307281494 seconds\n",
      "File 'CAX019_TOQUE_BANCA_D_20251009_20251010000624.CSV' inserted into the database: 0.727358341217041 seconds\n"
     ]
    }
   ],
   "source": [
    "from ftplib import FTP\n",
    "import os\n",
    "import io\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "import time\n",
    "\n",
    "current_year = datetime.datetime.now().year\n",
    "\n",
    "ftp = FTP()\n",
    "ftp.connect(host='10.0.25.193', port=2122)\n",
    "ftp.login(user='cax_sgc', passwd='gy768#lo')\n",
    "\n",
    "ftp.cwd('/OP/Rotas/Banca_Recolhas')\n",
    "\n",
    "files = ftp.nlst()\n",
    "\n",
    "def process_data(row):\n",
    "    try:\n",
    "        decoded_line = row.decode('Latin-1')\n",
    "    except UnicodeDecodeError as e:\n",
    "        print(f\"UnicodeDecodeError in file '{file}', line: {row}\")\n",
    "        decoded_line = row.decode('utf-8')\n",
    "    return decoded_line.strip()\n",
    "\n",
    "data_validation = []\n",
    "\n",
    "con = psycopg2.connect(host='localhost', \n",
    "                    database='ctt2025',\n",
    "                    user='postgres', \n",
    "                    password='1983')\n",
    "\n",
    "cur = con.cursor()\n",
    "\n",
    "cur.execute(\"SELECT distinct REPLACE(data, '.', '') dias FROM Banca_2025 order by dias asc\")\n",
    "for record in cur.fetchall():\n",
    "    if record[0] not in data_validation:\n",
    "        data_validation.append(record[0])\n",
    "\n",
    "cur.close()\n",
    "\n",
    "# Create a mapping between input column names and database column names\n",
    "column_mapping = {\n",
    "    'ï»¿COD_CLIENTE_BNC': 'COD_CLIENTE_BNC',\n",
    "    'CODIGO_BALCAO_SIDIR': 'CODIGO_BALCAO_SIDIR',\n",
    "    'CODIGO_BALCAO_AF': 'CODIGO_BALCAO_AF',\n",
    "    'AGENCIA': 'AGENCIA',\n",
    "    'CA': 'CA',\n",
    "    'CIRCUITO': 'CIRCUITO',\n",
    "    'DATA': 'DATA',\n",
    "    'CONTACTO': 'CONTACTO',\n",
    "    'FATURAR': 'FATURAR',\n",
    "    'ENTREGUE': 'ENTREGUE',\n",
    "    'TAREFA': 'TAREFA',\n",
    "    'CP': 'CP',\n",
    "    'CENTRO OPERACIONAL': 'CENTRO_OPERACIONAL',\n",
    "    'MORADA TOQUE': 'MORADA_TOQUE',\n",
    "    'HORA TOQUE PREVISTA': 'HORA_TOQUE_PREVISTA',\n",
    "    'HORA TOQUE REAL': 'HORA_TOQUE_REAL'\n",
    "}\n",
    "\n",
    "for file in files:\n",
    "    start_time = time.time()\n",
    "    if file.startswith(\"C\"):\n",
    "        date_str_s = file[21:29].replace(\"/\", \"\")\n",
    "        date_str_s_array = np.array(date_str_s)\n",
    "        ano = file[21:25]\n",
    "        if date_str_s not in data_validation and ano ==\"2025\":\n",
    "            \n",
    "            ftp = FTP()\n",
    "            ftp.connect(host='10.0.25.193', port=2122)\n",
    "            ftp.login(user='cax_sgc', passwd='gy768#lo')\n",
    "            ftp.cwd('/OP/Rotas/Banca_Recolhas')\n",
    "            \n",
    "            file_data = io.BytesIO()\n",
    "            ftp.retrbinary('RETR ' + file, file_data.write)\n",
    "            file_data.seek(0)  # Reset the stream position to the beginning\n",
    "\n",
    "            # Process the data line by line, excluding the last line\n",
    "            lines = file_data.readlines()\n",
    "            data_rows = [process_data(row) for row in lines[:-1]]  # Exclude the last line\n",
    "            \n",
    "            # Remove BOM if present\n",
    "            if data_rows and data_rows[0].startswith('\\ufeff'):\n",
    "                data_rows[0] = data_rows[0][1:]\n",
    "            \n",
    "            # Join the data_rows without the last line (to exclude the empty line) and convert to bytes\n",
    "            csv_data = '\\n'.join(data_rows[:-1]).encode('utf-8')\n",
    "            \n",
    "            # Decode the bytes data using utf-8-sig to handle the BOM\n",
    "            decoded_data = csv_data.decode('utf-8-sig')\n",
    "            \n",
    "            if decoded_data.strip():  # Check if the decoded data is not empty\n",
    "                # Create a DataFrame from the cleaned data rows\n",
    "                df = pd.read_csv(io.StringIO(decoded_data), sep=';', on_bad_lines='skip', encoding=\"Latin-1\")\n",
    "\n",
    "                # Rename the DataFrame columns based on the mapping\n",
    "                df.rename(columns=column_mapping, inplace=True)\n",
    "\n",
    "                # Insert the data into the database\n",
    "                try:\n",
    "                    cur = con.cursor()\n",
    "                    # Replace \"NaN\" values with None (NULL) for database insertion\n",
    "                    df = df.where(pd.notna(df), None)\n",
    "\n",
    "                    # Generate placeholders for the query based on the number of columns\n",
    "                    placeholders = ', '.join(['%s'] * len(df.columns))\n",
    "\n",
    "                    # Construct the INSERT query with placeholders\n",
    "                    insert_query = f\"INSERT INTO Banca_2025 ({', '.join(df.columns)}) VALUES ({placeholders})\"\n",
    "\n",
    "                    # Execute the query with the DataFrame values as parameters\n",
    "                    psycopg2.extras.execute_batch(cur, insert_query, df.values)\n",
    "                    con.commit()\n",
    "\n",
    "                    end_time = time.time()\n",
    "                    print(f\"File '{file}' inserted into the database: {end_time - start_time} seconds\")\n",
    "                except (Exception, psycopg2.DatabaseError) as error:\n",
    "                    print(f\"Error inserting data from file '{file}': {error}\")\n",
    "                    con.rollback()\n",
    "\n",
    "ftp.quit()\n",
    "con.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recolhas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "def conecta_db():\n",
    "      con = psycopg2.connect(host='localhost', \n",
    "                         database='ctt2025',\n",
    "                         user='postgres', \n",
    "                         password='1983')\n",
    "      return con\n",
    "\n",
    "\n",
    "def criar_db(sql):\n",
    "    con = conecta_db()\n",
    "    cur = con.cursor()\n",
    "    cur.execute(sql)\n",
    "    con.commit()\n",
    "    con.close()\n",
    "\n",
    "\n",
    "def inserir_db(sql):\n",
    "    con = conecta_db()\n",
    "    cur = con.cursor()\n",
    "    try:\n",
    "        cur.execute(sql)\n",
    "        con.commit()\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(\"Error: %s\" % error)\n",
    "        con.rollback()\n",
    "        cur.close()\n",
    "        return 1\n",
    "    cur.close()\n",
    "\n",
    "sql = '''CREATE TABLE IF NOT EXISTS Recolhas_2025 (\n",
    "            \"data_ficheiro\" text,\n",
    "            \"Código Orgânico\" text,\n",
    "            \"Descrição\" text,\n",
    "            \"Dia\" text,\n",
    "            \"Giro\" text,\n",
    "            \"Tipo\" text,\n",
    "            \"Ponto Recolha\" text,\n",
    "            \"Nome Cliente\" text,\n",
    "            \"Morada de recolha\" text,\n",
    "            \"Código postal recolha\" text,\n",
    "            \"Qntd de Objetos Recolhidos\" text,\n",
    "            \"Estado\" text,\n",
    "            \"Hora Início\" text,\n",
    "            \"Hora Fim\" text,\n",
    "            \"Hora Real\" text\n",
    "        )'''\n",
    "\n",
    "\n",
    "criar_db(sql)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20250624' '20250625' '20250626' '20250627' '20250628' '20250629'\n",
      " '20250630' '20250701' '20250702' '20250703' '20250704' '20250705'\n",
      " '20250706' '20250707' '20250708' '20250709' '20250710' '20250711'\n",
      " '20250712' '20250713' '20250714' '20250715' '20250716' '20250717'\n",
      " '20250718' '20250719' '20250720' '20250721' '20250722' '20250723'\n",
      " '20250724' '20250725' '20250726' '20250727' '20250728' '20250729'\n",
      " '20250730' '20250731' '20250801' '20250802' '20250803' '20250804'\n",
      " '20250805' '20250806' '20250807' '20250808' '20250809' '20250810'\n",
      " '20250811' '20250812' '20250813' '20250814' '20250815' '20250816'\n",
      " '20250817' '20250818' '20250819' '20250820' '20250821' '20250822'\n",
      " '20250823' '20250824' '20250825' '20250826' '20250827' '20250828'\n",
      " '20250829' '20250830' '20250831' '20250901' '20250902' '20250903'\n",
      " '20250904' '20250905' '20250906' '20250907' '20250908' '20250909'\n",
      " '20250910' '20250911' '20250912' '20250913' '20250914' '20250915'\n",
      " '20250916' '20250917' '20250918' '20250919' '20250920' '20250921'\n",
      " '20250922' '20250923' '20250924' '20250925' '20250926' '20250927'\n",
      " '20250928' '20250929' '20250930' '20251001' '20251002' '20251003'\n",
      " '20251004' '20251005']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "data_validation = []\n",
    "con = conecta_db()\n",
    "cur = con.cursor(cursor_factory=psycopg2.extras.DictCursor)\n",
    "\n",
    "cur.execute(\"SELECT DISTINCT  data_ficheiro as dias FROM Recolhas_2025  ORDER BY DIAS ASC\")\n",
    "for record in cur.fetchall():\n",
    "    if record[0] not in data_validation:\n",
    "        data_validation.append(record[0])\n",
    "cur.close()\n",
    "\n",
    "data_validation=np.array(data_validation)\n",
    "print(data_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'RECSG4366_RECOLHAS_20251006_20251007010501.CSV' inserted into the database: 6.681854248046875 seconds\n",
      "File 'RECSG4366_RECOLHAS_20251007_20251008010501.CSV' inserted into the database: 27.404104471206665 seconds\n",
      "File 'RECSG4366_RECOLHAS_20251008_20251009010500.CSV' inserted into the database: 18.166507244110107 seconds\n",
      "File 'RECSG4366_RECOLHAS_20251009_20251010010500.CSV' inserted into the database: 2.8839011192321777 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "import time\n",
    "from ftplib import FTP\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "import datetime\n",
    "\n",
    "\n",
    "current_year = datetime.datetime.now().year\n",
    "\n",
    "ftp = FTP()\n",
    "ftp.connect(host='10.0.25.193', port=2122)\n",
    "ftp.login(user='cax_sgc', passwd='gy768#lo')\n",
    "\n",
    "ftp.cwd('/OP/Rotas/Banca_Recolhas')\n",
    "\n",
    "files = ftp.nlst()\n",
    "\n",
    "def process_data(row):\n",
    "    try:\n",
    "        decoded_line = row.decode('Latin-1')\n",
    "    except UnicodeDecodeError as e:\n",
    "        print(f\"UnicodeDecodeError in file '{file}', line: {row}\")\n",
    "        decoded_line = row.decode('utf-8')\n",
    "    return decoded_line.strip()\n",
    "\n",
    "data_validation = []\n",
    "\n",
    "con = psycopg2.connect(host='localhost', \n",
    "                    database='ctt2025',\n",
    "                    user='postgres', \n",
    "                    password='1983')\n",
    "\n",
    "cur = con.cursor()\n",
    "\n",
    "cur.execute(\"SELECT DISTINCT  data_ficheiro as dias FROM Recolhas_2025  ORDER BY DIAS ASC\")\n",
    "\n",
    "for record in cur.fetchall():\n",
    "    if record[0] not in data_validation:\n",
    "        data_validation.append(record[0])\n",
    "\n",
    "# List of column names\n",
    "columns = ['\"Código Orgânico\"', '\"Descrição\"', '\"Dia\"', '\"Giro\"', '\"Tipo\"', '\"Ponto Recolha\"', '\"Nome Cliente\"',\n",
    "           '\"Morada de recolha\"', '\"Código postal recolha\"', '\"Qntd de Objetos Recolhidos\"', '\"Estado\"', '\"Hora Início\"',\n",
    "           '\"Hora Fim\"', '\"Hora Real\"']\n",
    "\n",
    "# Assuming you have a 'files' list defined earlier\n",
    "for file in files:\n",
    "    start_time = time.time()\n",
    "    if file.startswith(\"R\"):\n",
    "        date_str_s = file[19:27].replace(\"/\", \"\")\n",
    "        date_str_s_array = np.array(date_str_s)\n",
    "        ano = file[19:23]\n",
    "        if date_str_s not in data_validation and ano == \"2025\":\n",
    "\n",
    "            ftp = FTP()\n",
    "            ftp.connect(host='10.0.25.193', port=2122)\n",
    "            ftp.login(user='cax_sgc', passwd='gy768#lo')\n",
    "            ftp.cwd('/OP/Rotas/Banca_Recolhas')\n",
    "\n",
    "            file_data = io.BytesIO()\n",
    "            ftp.retrbinary('RETR ' + file, file_data.write)\n",
    "            file_data.seek(0)  # Reset the stream position to the beginning\n",
    "\n",
    "            # Process the data line by line, excluding the last line\n",
    "            lines = file_data.readlines()\n",
    "            data_rows = [process_data(row) for row in lines[:-1]]  # Exclude the last line\n",
    "\n",
    "            # Remove BOM if present\n",
    "            if data_rows and data_rows[0].startswith('\\ufeff'):\n",
    "                data_rows[0] = data_rows[0][1:]\n",
    "\n",
    "            # Join the data_rows without the last line (to exclude the empty line) and convert to bytes\n",
    "            csv_data = '\\n'.join(data_rows[:-1]).encode('utf-8')\n",
    "\n",
    "            # Decode the bytes data using utf-8-sig to handle the BOM\n",
    "            decoded_data = csv_data.decode('utf-8-sig')\n",
    "\n",
    "            if decoded_data.strip():  # Check if the decoded data is not empty\n",
    "                # Create a DataFrame from the cleaned data rows, specifying column names\n",
    "                df = pd.read_csv(io.StringIO(decoded_data), sep=';', names=columns, on_bad_lines='skip', encoding=\"Latin-1\")\n",
    "                df = df.iloc[1:]\n",
    "\n",
    "                # Add the 'data_ficheiro' column and fill it with date_str_s value\n",
    "                df['data_ficheiro'] = date_str_s\n",
    "\n",
    "                # Insert the data into the database\n",
    "                try:\n",
    "                    # Replace \"NaN\" values with None (NULL) for database insertion\n",
    "                    df = df.where(pd.notna(df), None)\n",
    "\n",
    "                    # Generate placeholders for the query based on the number of columns\n",
    "                    placeholders = ', '.join(['%s'] * len(df.columns))\n",
    "\n",
    "                    # Construct the INSERT query with placeholders\n",
    "                    insert_query = f\"INSERT INTO Recolhas_2025 ({', '.join(df.columns)}) VALUES ({placeholders})\"\n",
    "\n",
    "                    # Execute the query with the DataFrame values as parameters\n",
    "                    psycopg2.extras.execute_batch(cur, insert_query, df.values)\n",
    "                    con.commit()\n",
    "\n",
    "                    end_time = time.time()\n",
    "                    print(f\"File '{file}' inserted into the database: {end_time - start_time} seconds\")\n",
    "                except (Exception, psycopg2.DatabaseError) as error:\n",
    "                    print(f\"Error inserting data from file '{file}': {error}\")\n",
    "                    con.rollback()\n",
    "\n",
    "\n",
    "ftp.quit()\n",
    "con.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REDE BASE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "def conecta_db():\n",
    "      con = psycopg2.connect(host='localhost', \n",
    "                         database='ctt2025',\n",
    "                         user='postgres', \n",
    "                         password='1983')\n",
    "      return con\n",
    "\n",
    "\n",
    "def criar_db(sql):\n",
    "    con = conecta_db()\n",
    "    cur = con.cursor()\n",
    "    cur.execute(sql)\n",
    "    con.commit()\n",
    "    con.close()\n",
    "\n",
    "\n",
    "def inserir_db(sql):\n",
    "    con = conecta_db()\n",
    "    cur = con.cursor()\n",
    "    try:\n",
    "        cur.execute(sql)\n",
    "        con.commit()\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(\"Error: %s\" % error)\n",
    "        con.rollback()\n",
    "        cur.close()\n",
    "        return 1\n",
    "    cur.close()\n",
    "\n",
    "sql = ''' CREATE TABLE IF NOT EXISTS REDE_BASE_2025 (\n",
    "                                    DATA_CRIACAO      text,\n",
    "                                    CENTRO    text,\n",
    "                                    Giro text,\n",
    "                                    LOPTICA  text,\n",
    "                                    JANELA_HORARIA text,\n",
    "                                    NOME text,\n",
    "                                    MORADA text,\n",
    "                                    CP text,\n",
    "                                    LOCALIDADE text,\n",
    "                                    COD_T_EVEN text,\n",
    "                                    DATA_EVENTO text,\n",
    "                                    LATITUDE text,\n",
    "                                    LONGITUDE text,\n",
    "                                    NOME_REM text,\n",
    "                                    COD_PAIS_ORIGEM text) '''\n",
    "criar_db(sql)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20250624' '20250625' '20250626' '20250627' '20250628' '20250630'\n",
      " '20250701' '20250702' '20250703' '20250704' '20250705' '20250707'\n",
      " '20250708' '20250709' '20250710' '20250711' '20250712' '20250713'\n",
      " '20250714' '20250715' '20250716' '20250717' '20250718' '20250719'\n",
      " '20250720' '20250721' '20250722' '20250723' '20250724' '20250725'\n",
      " '20250726' '20250727' '20250728' '20250729' '20250730' '20250731'\n",
      " '20250801' '20250802' '20250803' '20250804' '20250805' '20250806'\n",
      " '20250807' '20250808' '20250809' '20250810' '20250811' '20250812'\n",
      " '20250813' '20250814' '20250815' '20250816' '20250817' '20250818'\n",
      " '20250819' '20250820' '20250821' '20250822' '20250823' '20250824'\n",
      " '20250825' '20250826' '20250827' '20250828' '20250829' '20250830'\n",
      " '20250831' '20250901' '20250902' '20250903' '20250904' '20250905'\n",
      " '20250906' '20250908' '20250909' '20250910' '20250911' '20250912'\n",
      " '20250913' '20250914' '20250915' '20250916' '20250917' '20250918'\n",
      " '20250919' '20250920' '20250921' '20250922' '20250923' '20250924'\n",
      " '20250925' '20250926' '20250927' '20250929' '20250930' '20251001'\n",
      " '20251002' '20251003' '20251004' 'NTCORO']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "data_validation = []\n",
    "con = conecta_db()\n",
    "cur = con.cursor(cursor_factory=psycopg2.extras.DictCursor)\n",
    "cur.execute(\"SELECT distinct  SUBSTRING(DATA_CRIACAO, 7, 4) ||  SUBSTRING(DATA_CRIACAO, 4, 2) ||  SUBSTRING(DATA_CRIACAO, 1, 2) as dias FROM REDE_BASE_2025 order by dias asc\")\n",
    "for record in cur.fetchall():\n",
    "    if record[0] not in data_validation:\n",
    "        data_validation.append(record[0])\n",
    "cur.close()\n",
    "\n",
    "data_validation=np.array(data_validation)\n",
    "print(data_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20250928\n",
      "File 'EVRBP4348_ENV_20250928_20250929010503.CSV' inserted into the database: 0.4058809280395508 seconds\n",
      "20251005\n",
      "File 'EVRBP4348_ENV_20251005_20251006010513.CSV' inserted into the database: 0.6961860656738281 seconds\n",
      "20251006\n",
      "File 'EVRBP4348_ENV_20251006_20251007010501.CSV' inserted into the database: 519.7565469741821 seconds\n",
      "20251007\n",
      "File 'EVRBP4348_ENV_20251007_20251008010502.CSV' inserted into the database: 572.1092419624329 seconds\n",
      "20251008\n",
      "File 'EVRBP4348_ENV_20251008_20251009010517.CSV' inserted into the database: 696.5280070304871 seconds\n",
      "20251009\n",
      "File 'EVRBP4348_ENV_20251009_20251010010500.CSV' inserted into the database: 792.761011838913 seconds\n"
     ]
    }
   ],
   "source": [
    "from ftplib import FTP\n",
    "import os\n",
    "import io\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "import time\n",
    "\n",
    "current_year = datetime.datetime.now().year\n",
    "\n",
    "ftp = FTP()\n",
    "ftp.connect(host='10.0.25.193', port=2122)\n",
    "ftp.login(user='cax_sgc', passwd='gy768#lo')\n",
    "\n",
    "ftp.cwd('/OP/Rotas/EventosPDA_Rede_base')\n",
    "\n",
    "files = ftp.nlst()\n",
    "\n",
    "def process_data(row):\n",
    "    try:\n",
    "        decoded_line = row.decode('Latin-1')\n",
    "    except UnicodeDecodeError as e:\n",
    "        print(f\"UnicodeDecodeError in file '{file}', line: {row}\")\n",
    "        decoded_line = row.decode('utf-8')\n",
    "\n",
    "    # Check if the number of columns is 13 (assuming semicolon as the delimiter)\n",
    "    if len(decoded_line.split(';')) == 13:\n",
    "        return decoded_line.strip()\n",
    "    else:\n",
    "        print(f\"Ignoring row with incorrect number of columns: {decoded_line}\")\n",
    "        return None  # Skip the row if it has an incorrect number of columns\n",
    "\n",
    "data_validation = []\n",
    "\n",
    "cur = con.cursor()\n",
    "\n",
    "cur.execute(\"SELECT distinct  SUBSTRING(DATA_CRIACAO, 7, 4) ||  SUBSTRING(DATA_CRIACAO, 4, 2) ||  SUBSTRING(DATA_CRIACAO, 1, 2) as dias FROM REDE_BASE_2025 order by dias asc\")\n",
    "for record in cur.fetchall():\n",
    "    if record[0] not in data_validation:\n",
    "        data_validation.append(record[0])\n",
    "\n",
    "cur.close()\n",
    "\n",
    "for file in files:\n",
    "    start_time = time.time()\n",
    "    if file.startswith(\"E\"):\n",
    "        date_str_s = file[14:22].replace(\"/\", \"\")\n",
    "        month = file[18:20].replace(\"/\", \"\")\n",
    "        date_str_s = np.array(date_str_s)\n",
    "        ano = file[14:18]\n",
    "        if date_str_s not in data_validation and month >= \"01\" and ano == \"2025\":\n",
    "            print(date_str_s)\n",
    "\n",
    "            ftp = FTP()\n",
    "            ftp.connect(host='10.0.25.193', port=2122)\n",
    "            ftp.login(user='cax_sgc', passwd='gy768#lo')\n",
    "            ftp.cwd('/OP/Rotas/EventosPDA_Rede_base')\n",
    "\n",
    "            file_data = io.BytesIO()\n",
    "            ftp.retrbinary('RETR ' + file, file_data.write)\n",
    "            file_data.seek(0)  # Reset the stream position to the beginning\n",
    "\n",
    "            try:\n",
    "                df = pd.read_csv(file_data, sep=';', on_bad_lines='skip', encoding=\"Latin-1\")\n",
    "            except pd.errors.ParserError as pe:\n",
    "                print(f\"ParserError occurred while reading CSV in file '{file}':\")\n",
    "                print(pe)\n",
    "                print(f\"Skipping file '{file}'.\")\n",
    "                continue\n",
    "\n",
    "            ftp.quit()\n",
    "\n",
    "            if len(df) == 0:\n",
    "                print(f\"All rows in file '{file}' were problematic. Skipping insertion.\")\n",
    "                continue\n",
    "            else:\n",
    "                # Create a DataFrame from the cleaned data rows\n",
    "\n",
    "                # Insert the data into the database\n",
    "                for index, row in df.iterrows():\n",
    "                    try:\n",
    "                        cur = con.cursor()\n",
    "                        # Replace \"NaN\" values with None (NULL) for database insertion\n",
    "                        row = [None if pd.isna(value) else value for value in row]\n",
    "                        placeholders = ', '.join(['%s'] * len(row))\n",
    "                        insert_query = f\"INSERT INTO REDE_BASE_2025 ({', '.join(df.columns)}) VALUES ({placeholders})\"\n",
    "                        cur.execute(insert_query, tuple(row))\n",
    "                    except (Exception, psycopg2.DatabaseError) as error:\n",
    "                        print(f\"Error inserting row {index+1} from file '{file}': {error}\")\n",
    "                        con.rollback()\n",
    "                    else:\n",
    "                        con.commit()\n",
    "\n",
    "                end_time = time.time()\n",
    "                print(f\"File '{file}' inserted into the database: {end_time - start_time} seconds\")\n",
    "\n",
    "con.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
